{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AJaysAIk/AI-Telegram-chatbot--Clarity-x1/blob/main/NLP_Enginner_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inD0m83RtDmB"
      },
      "outputs": [],
      "source": [
        "!pip install spacy datasets fastapi uvicorn pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssUfYeqsuvL6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the CoNLL-2003 dataset\n",
        "dataset = load_dataset(\"conll2003\")\n",
        "\n",
        "# Access train, validation, and test splits\n",
        "train_data = dataset[\"train\"]\n",
        "valid_data = dataset[\"validation\"]\n",
        "test_data = dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VrRMFqOruvOy"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.training import Example\n",
        "\n",
        "def convert_to_spacy_format(data):\n",
        "    spacy_data = []\n",
        "    for item in data:\n",
        "        text = \" \".join(item[\"tokens\"])\n",
        "        entities = []\n",
        "        start = 0\n",
        "        for token, tag in zip(item[\"tokens\"], item[\"ner_tags\"]):\n",
        "            end = start + len(token)\n",
        "            if tag != 0:  # 0 is 'O' (no entity)\n",
        "                # Map numeric tag to label (e.g., 1 -> \"B-PER\", simplified here)\n",
        "                label = train_data.features[\"ner_tags\"].feature.names[tag]\n",
        "                entities.append((start, end, label))\n",
        "            start = end + 1  # Account for space between tokens\n",
        "        spacy_data.append((text, {\"entities\": entities}))\n",
        "    return spacy_data\n",
        "\n",
        "# Convert datasets\n",
        "train_spacy = convert_to_spacy_format(train_data)\n",
        "valid_spacy = convert_to_spacy_format(valid_data)\n",
        "test_spacy = convert_to_spacy_format(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kv3omEJuvc_",
        "outputId": "da6ebd92-495d-4678-db64-327292a4d80e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Epoch 0, Losses: {'ner': 13388.059176656068}\n",
            "Epoch 1, Losses: {'ner': 5787.428180922152}\n",
            "Epoch 2, Losses: {'ner': 4035.1305129183015}\n",
            "Epoch 3, Losses: {'ner': 3146.1011637135603}\n",
            "Epoch 4, Losses: {'ner': 2526.496547476645}\n",
            "Epoch 5, Losses: {'ner': 2117.071306945934}\n",
            "Epoch 6, Losses: {'ner': 1953.8799516727697}\n",
            "Epoch 7, Losses: {'ner': 1665.241062070864}\n",
            "Epoch 8, Losses: {'ner': 1395.0527904438675}\n",
            "Epoch 9, Losses: {'ner': 1264.217857148425}\n",
            "Epoch 10, Losses: {'ner': 1190.2713842074074}\n",
            "Epoch 11, Losses: {'ner': 1130.5566890687883}\n",
            "Epoch 12, Losses: {'ner': 944.6374352266769}\n",
            "Epoch 13, Losses: {'ner': 996.6170158904142}\n",
            "Epoch 14, Losses: {'ner': 863.4668836630956}\n",
            "Epoch 15, Losses: {'ner': 913.6614795557617}\n",
            "Epoch 16, Losses: {'ner': 830.9698171600661}\n",
            "Epoch 17, Losses: {'ner': 811.3245761300665}\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "import spacy\n",
        "import random\n",
        "from spacy.util import minibatch\n",
        "from spacy.training import Example\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
        "train_data = dataset[\"train\"]\n",
        "valid_data = dataset[\"validation\"]\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "# Preprocessing\n",
        "def convert_to_spacy_format(data):\n",
        "    spacy_data = []\n",
        "    for item in data:\n",
        "        text = \" \".join(item[\"tokens\"])\n",
        "        entities = []\n",
        "        start = 0\n",
        "        current_entity = None\n",
        "        for token, tag in zip(item[\"tokens\"], item[\"ner_tags\"]):\n",
        "            end = start + len(token)\n",
        "            label = train_data.features[\"ner_tags\"].feature.names[tag]\n",
        "            if label.startswith(\"B-\"):\n",
        "                if current_entity:\n",
        "                    entities.append(current_entity)\n",
        "                current_entity = (start, end, label[2:])\n",
        "            elif label.startswith(\"I-\") and current_entity and label[2:] == current_entity[2]:\n",
        "                current_entity = (current_entity[0], end, current_entity[2])\n",
        "            elif current_entity:\n",
        "                entities.append(current_entity)\n",
        "                current_entity = None\n",
        "            start = end + 1\n",
        "        if current_entity:\n",
        "            entities.append(current_entity)\n",
        "        spacy_data.append((text, {\"entities\": entities}))\n",
        "    return spacy_data\n",
        "\n",
        "train_spacy = convert_to_spacy_format(train_data)\n",
        "valid_spacy = convert_to_spacy_format(valid_data)\n",
        "test_spacy = convert_to_spacy_format(test_data)\n",
        "\n",
        "# Training\n",
        "nlp = spacy.blank(\"en\")\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "labels = set(label[2:] for label in train_data.features[\"ner_tags\"].feature.names if label != \"O\")\n",
        "for label in labels:\n",
        "    ner.add_label(label)\n",
        "\n",
        "examples = [Example.from_dict(nlp.make_doc(text), annot) for text, annot in train_spacy]\n",
        "with nlp.disable_pipes(*[pipe for pipe in nlp.pipe_names if pipe != \"ner\"]):\n",
        "    optimizer = nlp.initialize()\n",
        "    for epoch in range(30):  # Increased to 35 epochs\n",
        "        random.shuffle(examples)\n",
        "        losses = {}\n",
        "        batches = minibatch(examples, size=8)\n",
        "        for batch in batches:\n",
        "            nlp.update(batch, sgd=optimizer, losses=losses)\n",
        "        print(f\"Epoch {epoch}, Losses: {losses}\")\n",
        "\n",
        "nlp.to_disk(\"/content/ner_model\")\n",
        "\n",
        "# Debug Predictions\n",
        "nlp = spacy.load(\"/content/ner_model\")\n",
        "text = \"John lives in New York\"\n",
        "doc = nlp(text)\n",
        "print(\"Sample Predictions:\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "# Evaluation\n",
        "scorer = Scorer()\n",
        "examples = []\n",
        "for text, annot in test_spacy[:100]:\n",
        "    doc = nlp(text)\n",
        "    pred_example = Example.from_dict(doc, annot)\n",
        "    examples.append(pred_example)\n",
        "\n",
        "scores = scorer.score(examples)\n",
        "print(f\"Precision: {scores['ents_p']:.2f}\")\n",
        "print(f\"Recall: {scores['ents_r']:.2f}\")\n",
        "print(f\"F1-Score: {scores['ents_f']:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RdSlsKMrs5PK"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI, HTTPException, Depends\n",
        "from fastapi.security import HTTPBasic, HTTPBasicCredentials\n",
        "from pydantic import BaseModel\n",
        "import spacy\n",
        "\n",
        "# Initialize FastAPI app and load the model\n",
        "app = FastAPI()\n",
        "security = HTTPBasic()\n",
        "nlp = spacy.load(\"/content/ner_model\")\n",
        "\n",
        "# Define input schema\n",
        "class TextInput(BaseModel):\n",
        "    text: str\n",
        "\n",
        "# Authentication function\n",
        "def verify_credentials(credentials: HTTPBasicCredentials = Depends(security)):\n",
        "    if credentials.username != \"admin\" or credentials.password != \"password\":\n",
        "        raise HTTPException(status_code=401, detail=\"Unauthorized\")\n",
        "    return True\n",
        "\n",
        "@app.get(\"/hello\")\n",
        "async def read_hello():\n",
        "    return {\"message\": \"Hello, world!\"}\n",
        "\n",
        "\n",
        "# Prediction endpoint\n",
        "@app.post(\"/predict\")\n",
        "def predict(input: TextInput, auth: bool = Depends(verify_credentials)):\n",
        "    if not input.text:\n",
        "        raise HTTPException(status_code=400, detail=\"Text input required\")\n",
        "    doc = nlp(input.text)\n",
        "    entities = [{\"text\": ent.text, \"label\": ent.label_} for ent in doc.ents]\n",
        "    return {\"entities\": entities}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "# Set your ngrok authtoken (replace with your actual token)\n",
        "ngrok.set_auth_token(\"2uABFAkcvmIjmgVHYebtEovHfwc_2bHesjMKse3ZA79bEiyRR\")\n",
        "\n",
        "# Define your app if you haven't already (make sure `app` is defined)\n",
        "# For example:\n",
        "# from fastapi import FastAPI\n",
        "# app = FastAPI()\n",
        "\n",
        "# Run Uvicorn in a separate thread\n",
        "def run():\n",
        "    # Optionally change the port if 8000 is taken\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8005)\n",
        "\n",
        "thread = threading.Thread(target=run)\n",
        "thread.start()\n",
        "\n",
        "# Create an Ngrok tunnel to port 8000 (or your chosen port)\n",
        "public_url = ngrok.connect(8005)\n",
        "print(f\"Public URL: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNy1uH6pR_jw",
        "outputId": "1f83f5ac-6cc3-4d29-f093-44186b8e622c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [8823]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8005 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://3788-34-106-144-35.ngrok-free.app\" -> \"http://localhost:8005\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "xhPAbhnbR_nq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jRo4Q4I1R_qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tXJ65ZxR_so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ZvnpStWR_v8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nkov1WOR_yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2sMlWRjR_0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jl4add2YR_4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4jUGpNOSBa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHt8RRJ3SBeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gGdFP-H7SBiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lqV8frHXSBk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDXxGT3Ds5YE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKM7Frh5iut0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AY1di39iuxg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGCUcQQ1iu1B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgODEEz7iu5C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA8Swg62iu8b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnGbzUj6QcUT4oCFpKmRWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}